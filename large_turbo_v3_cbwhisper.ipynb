{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and the correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.55.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: datasets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: librosa in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (4.14.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "/home/zeus/miniconda3/lib/python3.10/site-packages/conda/base/context.py:211: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.9. \n",
      "\n",
      "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
      "\n",
      "  conda config --add channels defaults\n",
      "\n",
      "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
      "\n",
      "  deprecated.topic(\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.5.1\n",
      "    latest version: 25.7.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: torchcodec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: sentence_transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (4.55.0)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence_transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.7)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from triton==3.4.0->torch>=1.11.0->sentence_transformers) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: tf-keras in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.11.1)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (14.1.0)\n",
      "Requirement already satisfied: namex in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n",
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.34.4)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: pip in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (25.2)\n",
      "zsh:1: no matches found: datasets[audio]\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install librosa\n",
    "!pip install --upgrade --quiet pip\n",
    "!pip install --upgrade --quiet datasets==3.6.0 transformers accelerate soundfile evaluate jiwer tensorboard gradio tensorflow\n",
    "!conda install -c conda-forge ffmpeg -y\n",
    "!pip install torchcodec\n",
    "!pip install sentence_transformers\n",
    "!pip install tf-keras\n",
    "!pip install evaluate\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade transformers datasets[audio] accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/teamspace/studios/this_studio/sentence_audios/上水, 彩蒲苑.wav',\n",
       " '/teamspace/studios/this_studio/sentence_audios/北角, 百福花園.wav',\n",
       " '/teamspace/studios/this_studio/sentence_audios/屯門, 澤豐花園.wav',\n",
       " '/teamspace/studios/this_studio/sentence_audios/沙田, 中文大學.wav',\n",
       " '/teamspace/studios/this_studio/sentence_audios/沙田, 富安花園.wav',\n",
       " '/teamspace/studios/this_studio/sentence_audios/粉嶺, 祥華邨.wav',\n",
       " '/teamspace/studios/this_studio/sentence_audios/葵涌, 清麗苑.wav',\n",
       " '/teamspace/studios/this_studio/sentence_audios/薄扶林, 碧瑤灣.wav',\n",
       " '/teamspace/studios/this_studio/sentence_audios/西灣河, 寶蕊樓.wav',\n",
       " '/teamspace/studios/this_studio/sentence_audios/鰂魚涌, 寶峰園.wav']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "audio_folder_path='/teamspace/studios/this_studio/sentence_audios'\n",
    "sentence_audio_file=[]\n",
    "unique_location=[]\n",
    "for file in os.listdir(audio_folder_path):\n",
    "    if file.lower().endswith('.wav'):\n",
    "        sentence_audio_file.append(os.path.join(audio_folder_path, file))\n",
    "        unique_location.append(file.replace('.wav', '').replace(', ', ''))\n",
    "sentence_audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['上水彩蒲苑',\n",
       " '北角百福花園',\n",
       " '屯門澤豐花園',\n",
       " '沙田中文大學',\n",
       " '沙田富安花園',\n",
       " '粉嶺祥華邨',\n",
       " '葵涌清麗苑',\n",
       " '薄扶林碧瑤灣',\n",
       " '西灣河寶蕊樓',\n",
       " '鰂魚涌寶峰園']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['上水彩蒲苑預約拆除石油氣錶',\n",
       " '沙田富安花園預約抄錶',\n",
       " '西灣河寶蕊樓預約檢查及維修煮食爐',\n",
       " '預約屯門澤豐花園叫氣',\n",
       " '粉嶺祥華邨預約爐具安裝煮食爐',\n",
       " '鰂魚涌寶峰園預約檢查及維修其他',\n",
       " '葵涌清麗苑預約安裝石油氣錶',\n",
       " '我既屋企係薄扶林碧瑤灣',\n",
       " '北角百福花園預約檢查及維修喉管',\n",
       " '我係沙田中文大學讀緊書']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_answer_path='/teamspace/studios/this_studio/scripts/script.txt'\n",
    "correct_answer=[]\n",
    "with open(correct_answer_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        correct_answer.append(line.strip())\n",
    "correct_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上載large turbo v3並讀取輸出結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import glob\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.55.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.55.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 10:41:05.280344: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-12 10:41:05.303857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754995265.329162   60218 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754995265.337817   60218 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754995265.361257   60218 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754995265.361281   60218 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754995265.361283   60218 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754995265.361285   60218 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-12 10:41:05.368201: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "# forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"zh\", task=\"transcribe\", \"repetition_penalty\": 1.5,)\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    generate_kwargs={\n",
    "        # \"forced_decoder_ids\": forced_decoder_ids\n",
    "        \"language\": \"zh\",  # 指定中文輸出\n",
    "        \"task\": \"transcribe\",\n",
    "        \"temperature\": 0.0,  # 關閉隨機性\n",
    "        \"repetition_penalty\": 1.5,  # 抑制重複\n",
    "        # \"no_repeat_ngram_size\": 1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上水彩蒲丸欲約拆除石油氣表\n",
      "北角百福花園預約檢查及維修喉管\n",
      "預約屯門閘風花園叫戲\n",
      "我是沙田中文大學正在讀書\n",
      "沙田庫安花園預約抽表\n",
      "粉領長華村預約爐具安裝、煮食爐\n",
      "葵聰清麗院預約安裝石油氣表\n",
      "我的家是薄乎臨壁搖灣\n",
      "西灣河保瑞樓預約檢查及維修主食爐\n",
      "質疑中補風源預約檢查及維修其他\n"
     ]
    }
   ],
   "source": [
    "predicted_result=[]\n",
    "for file in sentence_audio_file:\n",
    "    result = pipe(file)\n",
    "    print(result['text'])\n",
    "    predicted_result.append(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "wer_score = wer.compute(predictions=predicted_result, references=correct_answer)\n",
    "print(wer_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入BC Whisper進行測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['上水彩蒲苑',\n",
       " '北角百福花園',\n",
       " '屯門澤豐花園',\n",
       " '沙田中文大學',\n",
       " '沙田富安花園',\n",
       " '粉嶺祥華邨',\n",
       " '葵涌清麗苑',\n",
       " '薄扶林碧瑤灣',\n",
       " '西灣河寶蕊樓',\n",
       " '鰂魚涌寶峰園']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "�\n",
      "園\n",
      "園�\n",
      "園園\n",
      "園園�\n",
      "園園園\n",
      "園園園�\n",
      "園園園園\n",
      "園園園園�\n",
      "園園園園園\n",
      "園園園園園�\n",
      "園園園園園園\n",
      "園園園園園園�\n",
      "園園園園園園園\n",
      "園園園園園園園�\n",
      "園園園園園園園園\n",
      "園園園園園園園園�\n",
      "園園園園園園園園園\n",
      "園園園園園園園園園�\n",
      "園園園園園園園園園園\n",
      "園園園園園園園園園園�\n",
      "園園園園園園園園園園園\n",
      "園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園��\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園��\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園��\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園����\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�����������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園������������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園�������������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園��������������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園���������������������������������������������������������������\n",
      "園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園園�園�園園���園����������������������������������������������������������������\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from transformers import LogitsProcessor\n",
    "import numpy as np\n",
    "\n",
    "# 初始化模型和設備\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# --- 核心改動：CB Whisper 實現 ---\n",
    "# 1. 定義偏置詞表和地名列表 (根據您提供的標準答案)\n",
    "bias_terms = {\n",
    "    # 地名修正 (權重最高)\n",
    "    \"彩蒲苑\": 20.0, \"富安花園\": 20.0, \"寶蕊樓\": 20.0,\n",
    "    \"澤豐花園\": 20.0, \"祥華邨\": 20.0, \"寶峰園\": 20.0,\n",
    "    \"清麗苑\": 20.0, \"碧瑤灣\": 20.0, \"百福花園\": 20.0,\n",
    "    \n",
    "    # 粵語專用字\n",
    "    \"錶\": 15.0, \"喺\": 12.0, \"咗\": 12.0, \"嘅\": 10.0,\n",
    "    \"讀緊\": 10.0, \"屋企\": 10.0, \"預約\": 8.0,\n",
    "    \n",
    "    # 行業詞彙\n",
    "    \"煮食爐\": 15.0, \"石油氣\": 10.0, \"喉管\": 10.0\n",
    "}\n",
    "\n",
    "place_names = [\n",
    "    '上水彩蒲苑', '沙田富安花園', '西灣河寶蕊樓',\n",
    "    '屯門澤豐花園', '粉嶺祥華邨', '鰂魚涌寶峰園',\n",
    "    '葵涌清麗苑', '薄扶林碧瑤灣', '北角百福花園'\n",
    "]\n",
    "\n",
    "# 2. 自定義Logits Processor\n",
    "class CantoneseLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self, processor, bias_terms, place_names):\n",
    "        self.processor = processor\n",
    "        self.bias_terms = bias_terms\n",
    "        self.place_names = place_names\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        # 獲取當前已生成的文本\n",
    "        decoded_text = self.processor.decode(input_ids[0], skip_special_tokens=True)\n",
    "        print(decoded_text)\n",
    "        # (A) 靜態詞表偏置\n",
    "        for term, bias in self.bias_terms.items():\n",
    "            term_ids = self.processor.tokenizer.encode(term, add_special_tokens=False)\n",
    "            for term_id in term_ids:\n",
    "                scores[0, term_id] += bias\n",
    "\n",
    "        # (B) 地名模糊匹配修正\n",
    "        for place in self.place_names:\n",
    "            if place[:2] in decoded_text:  # 部分匹配觸發\n",
    "                place_ids = self.processor.tokenizer.encode(place, add_special_tokens=False)\n",
    "                for pid in place_ids:\n",
    "                    scores[0, pid] += 25.0  # 極高權重\n",
    "\n",
    "        # (C) 語法規則：檢測\"預約\"後應接動詞\n",
    "        if \"預約\" in decoded_text[-5:]:\n",
    "            for verb in [\"拆除\", \"安裝\", \"檢查\", \"維修\", \"抄\"]:\n",
    "                verb_ids = self.processor.tokenizer.encode(verb, add_special_tokens=False)\n",
    "                for vid in verb_ids:\n",
    "                    scores[0, vid] += 10.0\n",
    "\n",
    "        return scores\n",
    "\n",
    "# 3. 初始化Pipeline並注入Processor\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    generate_kwargs={\n",
    "        \"language\": \"zh\",\n",
    "        \"task\": \"transcribe\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"repetition_penalty\": 1.5,\n",
    "        \"logits_processor\": [CantoneseLogitsProcessor(processor, bias_terms, place_names)]\n",
    "    }\n",
    ")\n",
    "\n",
    "# # 4. 後處理函數 (基於規則修正)\n",
    "# def cantonese_postprocess(text):\n",
    "#     replacements = {\n",
    "#         r\"石油氣表\": \"石油氣錶\",\n",
    "#         r\"正在讀書\": \"讀緊書\",\n",
    "#         r\"我的家是\": \"我屋企係\",\n",
    "#         r\"預約抽表\": \"預約抄錶\"\n",
    "#     }\n",
    "#     for pattern, repl in replacements.items():\n",
    "#         text = re.sub(pattern, repl, text)\n",
    "#     return text\n",
    "\n",
    "# --- 使用示例 ---\n",
    "for file in sentence_audio_file[:1]:\n",
    "    result = pipe(file)\n",
    "    # final_text = cantonese_postprocess(result[\"text\"])\n",
    "    # print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 02:55:43.036434: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-13 02:55:43.064479: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755053743.088685   21175 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755053743.098023   21175 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755053743.119440   21175 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755053743.119471   21175 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755053743.119474   21175 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755053743.119476   21175 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-13 02:55:43.126634: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "from transformers import WhisperModel, WhisperProcessor\n",
    "import librosa\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class KeywordSpottingConfig:\n",
    "    \"\"\"Configuration for keyword spotting module\"\"\"\n",
    "    cnn_channels: List[int] = None\n",
    "    kernel_sizes: List[int] = None\n",
    "    pooling_sizes: List[int] = None\n",
    "    dropout_rate: float = 0.3\n",
    "    detection_threshold: float = 0.7\n",
    "    max_keywords_per_utterance: int = 5\n",
    "    def __post_init__(self):\n",
    "        if self.cnn_channels is None:\n",
    "            self.cnn_channels = [256, 512, 512, 256]\n",
    "        if self.kernel_sizes is None:\n",
    "            self.kernel_sizes = [3, 3, 3, 3]\n",
    "        if self.pooling_sizes is None:\n",
    "            self.pooling_sizes = [2, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordSpottingModule(nn.Module):\n",
    "    def __init__(self,input_dim: int,num_keywords: int,config: KeywordSpottingConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.num_keywords = num_keywords\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i, (out_channels, kernel_size, pool_size) in enumerate(zip(config.cnn_channels, config.kernel_sizes, config.pooling_sizes)):\n",
    "            layers.extend([\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(pool_size),\n",
    "                nn.Dropout(config.dropout_rate)\n",
    "            ])\n",
    "            in_channels = out_channels\n",
    "        self.cnn_layers = nn.Sequential(*layers)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Linear(config.cnn_channels[-1], num_keywords)\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=input_dim,\n",
    "            num_heads=8,\n",
    "            dropout=config.dropout_rate\n",
    "        )\n",
    "    def forward(self, encoder_hidden_states: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass for keyword spotting\n",
    "        Args:\n",
    "            encoder_hidden_states: [batch_size, seq_len, hidden_dim]\n",
    "        Returns:\n",
    "            keyword_probs: [batch_size, num_keywords]\n",
    "            attention_weights: [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, hidden_dim = encoder_hidden_states.shape\n",
    "        attended_features, attention_weights = self.attention(\n",
    "            encoder_hidden_states.transpose(0, 1),  # [seq_len, batch_size, hidden_dim]\n",
    "            encoder_hidden_states.transpose(0, 1),\n",
    "            encoder_hidden_states.transpose(0, 1)\n",
    "        )\n",
    "        attended_features = attended_features.transpose(0, 1)\n",
    "        cnn_input = attended_features.reshape(batch_size, 1, -1)\n",
    "        cnn_output = self.cnn_layers(cnn_input)\n",
    "        pooled_features = self.global_pool(cnn_output).squeeze(-1)\n",
    "        keyword_probs = torch.sigmoid(self.classifier(pooled_features))\n",
    "        attention_weights = attention_weights.mean(dim=1)\n",
    "        return keyword_probs, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTSKeywordGenerator:\n",
    "    \"\"\"Generate synthetic audio for keyword training using TTS\"\"\"\n",
    "    def __init__(self, tts_model_name: str = \"microsoft/speecht5_tts\"):\n",
    "        self.tts_model = None\n",
    "        self.sample_rate = 16000\n",
    "    def generate_keyword_audio(self, keyword: str, num_samples: int = 10,contexts: List[str] = None) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate synthetic audio samples for a keyword\n",
    "        Args:\n",
    "            keyword: Target keyword\n",
    "            num_samples: Number of audio samples to generate\n",
    "            contexts: Optional context sentences\n",
    "        Returns:\n",
    "            List of audio arrays\n",
    "        \"\"\"\n",
    "        if contexts is None:\n",
    "            contexts = [\n",
    "                f\"The keyword is {keyword}.\",\n",
    "                f\"Please recognize {keyword} correctly.\",\n",
    "                f\"I mentioned {keyword} in my speech.\",\n",
    "                f\"The term {keyword} is important.\",\n",
    "                f\"Can you hear {keyword} clearly?\"\n",
    "            ]\n",
    "        audio_samples = []\n",
    "        for i in range(num_samples):\n",
    "            context = contexts[i % len(contexts)]\n",
    "            duration = len(context.split()) * 0.3  # Rough estimate\n",
    "            num_samples_audio = int(duration * self.sample_rate)\n",
    "            audio = np.random.randn(num_samples_audio) * 0.1  # Placeholder\n",
    "            audio_samples.append(audio)\n",
    "        return audio_samples\n",
    "    def create_training_dataset(self,keywords: List[str],samples_per_keyword: int = 20) -> Tuple[List[np.ndarray], List[int]]:\n",
    "        \"\"\"\n",
    "        Create training dataset for keyword spotting\n",
    "        Returns:\n",
    "            audio_samples: List of audio arrays\n",
    "            labels: List of keyword indices\n",
    "        \"\"\"\n",
    "        all_audio = []\n",
    "        all_labels = []\n",
    "        for keyword_idx, keyword in enumerate(keywords):\n",
    "            keyword_audio = self.generate_keyword_audio(\n",
    "                keyword, \n",
    "                num_samples=samples_per_keyword\n",
    "            )\n",
    "            all_audio.extend(keyword_audio)\n",
    "            all_labels.extend([keyword_idx] * len(keyword_audio))\n",
    "        return all_audio, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptGenerator:\n",
    "    \"\"\"Generate contextual prompts based on detected keywords\"\"\"\n",
    "    def __init__(self, keywords: List[str]):\n",
    "        self.keywords = keywords\n",
    "        self.keyword_to_idx = {kw: idx for idx, kw in enumerate(keywords)}\n",
    "    def generate_prompt(self,detected_keywords: List[int],confidence_scores: List[float]) -> str:\n",
    "        \"\"\"\n",
    "        Generate contextual prompt based on detected keywords\n",
    "        Args:\n",
    "            detected_keywords: List of detected keyword indices\n",
    "            confidence_scores: Confidence scores for each detection\n",
    "        Returns:\n",
    "            Generated prompt string\n",
    "        \"\"\"\n",
    "        if not detected_keywords:\n",
    "            return \"\"\n",
    "        keyword_conf_pairs = list(zip(detected_keywords, confidence_scores))\n",
    "        keyword_conf_pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "        prompt_keywords = []\n",
    "        for keyword_idx, conf in keyword_conf_pairs[:3]:  # Top 3 keywords\n",
    "            if conf > 0.5:  # Confidence threshold\n",
    "                prompt_keywords.append(self.keywords[keyword_idx])\n",
    "        if not prompt_keywords:\n",
    "            return \"\"\n",
    "        if len(prompt_keywords) == 1:\n",
    "            prompt = f\"The following transcript contains the term {prompt_keywords[0]}.\"\n",
    "        elif len(prompt_keywords) == 2:\n",
    "            prompt = f\"The following transcript contains {prompt_keywords[0]} and {prompt_keywords[1]}.\"\n",
    "        else:\n",
    "            prompt = f\"The following transcript contains {', '.join(prompt_keywords[:-1])}, and {prompt_keywords[-1]}.\"\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBWhisperSystem:\n",
    "    \"\"\"Complete CB-Whisper system implementation\"\"\"\n",
    "    def __init__(self, whisper_model_name: str = \"openai/whisper-small\",keywords: List[str] = None,config: KeywordSpottingConfig = None, device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.device = device\n",
    "        self.processor = WhisperProcessor.from_pretrained(whisper_model_name)\n",
    "        self.whisper_model = WhisperModel.from_pretrained(whisper_model_name).to(self.device)\n",
    "        self.keywords = keywords or []\n",
    "        self.config = config or KeywordSpottingConfig()\n",
    "        if self.keywords:\n",
    "            self.kws_module = KeywordSpottingModule(\n",
    "                input_dim=self.whisper_model.config.d_model,\n",
    "                num_keywords=len(self.keywords),\n",
    "                config=self.config\n",
    "            ).to(self.device)\n",
    "            self.prompt_generator = PromptGenerator(self.keywords)\n",
    "            self.tts_generator = TTSKeywordGenerator()\n",
    "        self.is_trained = False\n",
    "    def train_keyword_spotting(self, num_epochs: int = 50,batch_size: int = 16,learning_rate: float = 1e-4):\n",
    "        \"\"\"\n",
    "        Train the keyword spotting module\n",
    "        \"\"\"\n",
    "        if not self.keywords:\n",
    "            raise ValueError(\"No keywords provided for training\")\n",
    "        print(\"Generating synthetic training data...\")\n",
    "        audio_samples, labels = self.tts_generator.create_training_dataset(\n",
    "            self.keywords, \n",
    "            samples_per_keyword=50\n",
    "        )\n",
    "        train_features = []\n",
    "        train_labels = []\n",
    "        for audio, label in zip(audio_samples, labels):\n",
    "            inputs = self.processor(\n",
    "                audio, \n",
    "                sampling_rate=16000, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                input_features = inputs.input_features.to(self.device)\n",
    "                encoder_outputs = self.whisper_model.encoder(input_features)\n",
    "                features = encoder_outputs.last_hidden_state.cpu()\n",
    "            train_features.append(features.squeeze(0))\n",
    "            label_vector = torch.zeros(len(self.keywords))\n",
    "            label_vector[label] = 1.0\n",
    "            train_labels.append(label_vector)\n",
    "        optimizer = torch.optim.Adam(self.kws_module.parameters(), lr=learning_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "        self.kws_module.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0.0\n",
    "            num_batches = 0\n",
    "            for i in range(0, len(train_features), batch_size):\n",
    "                batch_features = train_features[i:i+batch_size]\n",
    "                batch_labels = train_labels[i:i+batch_size]\n",
    "                if len(batch_features) < batch_size:\n",
    "                    continue\n",
    "                max_len = max(f.shape[0] for f in batch_features)\n",
    "                padded_features = []\n",
    "                for features in batch_features:\n",
    "                    if features.shape[0] < max_len:\n",
    "                        padding = torch.zeros(\n",
    "                            max_len - features.shape[0], \n",
    "                            features.shape[1]\n",
    "                        )\n",
    "                        features = torch.cat([features, padding], dim=0)\n",
    "                    padded_features.append(features)\n",
    "                batch_features_tensor = torch.stack(padded_features).to(self.device)\n",
    "                batch_labels_tensor = torch.stack(batch_labels).to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                keyword_probs, _ = self.kws_module(batch_features_tensor)\n",
    "                loss = criterion(keyword_probs, batch_labels_tensor)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "            avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "        self.is_trained = True\n",
    "        print(\"Keyword spotting training completed!\")\n",
    "    def transcribe_with_keyword_spotting(self, audio_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Transcribe audio with keyword spotting enhancement\n",
    "        Returns:\n",
    "            Dictionary containing transcription and keyword detection results\n",
    "        \"\"\"\n",
    "        if not self.is_trained and self.keywords:\n",
    "            print(\"Warning: Keyword spotting module not trained. Training now...\")\n",
    "            self.train_keyword_spotting()\n",
    "        audio, sr = librosa.load(audio_path, sr=16000)\n",
    "        inputs = self.processor(audio, sampling_rate=16000, return_tensors=\"pt\")\n",
    "        input_features = inputs.input_features.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs = self.whisper_model.encoder(input_features)\n",
    "            encoder_hidden_states = encoder_outputs.last_hidden_state\n",
    "        detected_keywords = []\n",
    "        keyword_confidences = []\n",
    "        prompt = \"\"\n",
    "        if self.keywords and self.is_trained:\n",
    "            self.kws_module.eval()\n",
    "            with torch.no_grad():\n",
    "                keyword_probs, attention_weights = self.kws_module(encoder_hidden_states)\n",
    "                keyword_probs = keyword_probs.cpu()\n",
    "                for i, prob in enumerate(keyword_probs.squeeze()):\n",
    "                    if prob > self.config.detection_threshold:\n",
    "                        detected_keywords.append(i)\n",
    "                        keyword_confidences.append(prob.item())\n",
    "                if detected_keywords:\n",
    "                    prompt = self.prompt_generator.generate_prompt(\n",
    "                        detected_keywords, keyword_confidences\n",
    "                    )\n",
    "        if prompt:\n",
    "            transcription_inputs = self.processor(\n",
    "                audio, \n",
    "                sampling_rate=16000, \n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            input_features = transcription_inputs.input_features.to(self.device)\n",
    "            generated_ids = self.whisper_model.generate(input_features)\n",
    "        else:\n",
    "            generated_ids = self.whisper_model.generate(input_features)\n",
    "        transcription = self.processor.batch_decode(\n",
    "            generated_ids, \n",
    "            skip_special_tokens=True\n",
    "        )[0]\n",
    "        detected_keyword_names = [\n",
    "            self.keywords[idx] for idx in detected_keywords\n",
    "        ]\n",
    "        return {\n",
    "            \"transcription\": transcription,\n",
    "            \"detected_keywords\": detected_keyword_names,\n",
    "            \"keyword_confidences\": keyword_confidences,\n",
    "            \"generated_prompt\": prompt,\n",
    "            \"attention_weights\": attention_weights.squeeze().numpy() if self.keywords else None\n",
    "        }\n",
    "\n",
    "def demonstrate_cb_whisper():\n",
    "    # \"\"\"\n",
    "    #  Demonstrate CB-Whisper implementation\n",
    "    # \"\"\"\n",
    "    \"\"\"\n",
    "    Demonstrate CB-Whisper implementation on GPU\n",
    "    \"\"\"\n",
    "    keywords = [\n",
    "        \"OpenAI\", \"Microsoft\", \"Google\", \"Amazon\", \"Apple\",\n",
    "        \"TensorFlow\", \"PyTorch\", \"Kubernetes\", \"Docker\",\n",
    "        \"San Francisco\", \"New York\", \"Seattle\", \"Boston\"\n",
    "    ]\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    # Initialize CB-Whisper system\n",
    "    cb_whisper = CBWhisperSystem(\n",
    "        whisper_model_name=\"openai/whisper-small\",\n",
    "        keywords=keywords,\n",
    "        config=KeywordSpottingConfig(detection_threshold=0.6),\n",
    "        device=device\n",
    "    )\n",
    "    print(\"Training keyword spotting module...\")\n",
    "    cb_whisper.train_keyword_spotting(num_epochs=10, batch_size=4)\n",
    "    return cb_whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training keyword spotting module...\n",
      "Generating synthetic training data...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 21.96 GiB of which 2.37 GiB is free. Process 68393 has 19.59 GiB memory in use. Of the allocated memory 16.88 GiB is allocated by PyTorch, and 2.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     system \u001b[38;5;241m=\u001b[39m \u001b[43mdemonstrate_cb_whisper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCB-Whisper system initialized and trained successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 157\u001b[0m, in \u001b[0;36mdemonstrate_cb_whisper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m cb_whisper \u001b[38;5;241m=\u001b[39m CBWhisperSystem(\n\u001b[1;32m    151\u001b[0m     whisper_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/whisper-small\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m     keywords\u001b[38;5;241m=\u001b[39mkeywords,\n\u001b[1;32m    153\u001b[0m     config\u001b[38;5;241m=\u001b[39mKeywordSpottingConfig(detection_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m),\n\u001b[1;32m    154\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    155\u001b[0m )\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining keyword spotting module...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m \u001b[43mcb_whisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_keyword_spotting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cb_whisper\n",
      "Cell \u001b[0;32mIn[8], line 69\u001b[0m, in \u001b[0;36mCBWhisperSystem.train_keyword_spotting\u001b[0;34m(self, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     67\u001b[0m batch_labels_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(batch_labels)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 69\u001b[0m keyword_probs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkws_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_features_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(keyword_probs, batch_labels_tensor)\n\u001b[1;32m     71\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[3], line 42\u001b[0m, in \u001b[0;36mKeywordSpottingModule.forward\u001b[0;34m(self, encoder_hidden_states)\u001b[0m\n\u001b[1;32m     40\u001b[0m attended_features \u001b[38;5;241m=\u001b[39m attended_features\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     41\u001b[0m cnn_input \u001b[38;5;241m=\u001b[39m attended_features\u001b[38;5;241m.\u001b[39mreshape(batch_size, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m cnn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m pooled_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_pool(cnn_output)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m keyword_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(pooled_features))\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/container.py:244\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/pooling.py:145\u001b[0m, in \u001b[0;36mMaxPool1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_jit_internal.py:627\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 627\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py:737\u001b[0m, in \u001b[0;36m_max_pool1d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    736\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 737\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 21.96 GiB of which 2.37 GiB is free. Process 68393 has 19.59 GiB memory in use. Of the allocated memory 16.88 GiB is allocated by PyTorch, and 2.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    system = demonstrate_cb_whisper()\n",
    "    print(\"CB-Whisper system initialized and trained successfully\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
